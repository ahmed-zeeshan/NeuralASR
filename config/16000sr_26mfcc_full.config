[Parameters]
#### Audio sample rate
samplerate=16000

#### Number of MFCC to compute
numcep=26

#### Number of MFCCs take into account in context. The feature vector size will be "(2 * numcontext + 1) * numcep"
numcontext=10

#### Define the context for the acoustic units.
label_context=0

#### randomly shift feature vector to avoid over-fitting
#rand_shift=2

#### Batch size for training neural network
batch_size=32

#### Number of iterations over complete training data.
epochs=10000

#### Learning rate of for optimizer
learningrate=0.01

#### Path where trained models are saved.
model_dir=.model

#### if greater than zero model will be loaded from mode_dir
start_step=0

#### status will be  printed after 'report_step' batches
report_step=100

#### Number of GPUs to use
num_gpus=4

#### Remove punctuations from the labels
punc_regex=[^a-z0-9 ]

#### File where Output symbols are stored e.g. [a,b,c...] with their numeric ids
sym_file=${MFCC Featurizer:output}/symbols

#### Network to use for the ASR
network=networks.deepspeech.DeepSpeech

[Train]
#### File containing list of .pkl file generated from preprocess_mfcc.py
input=${MFCC Featurizer:output}/train.scp

[Test]
#### File containing list of .pkl file generated from preprocess_mfcc.py
input=${MFCC Featurizer:output}/test.scp

[MFCC Featurizer]
#### CSV File containing audio file path, transcription, audio size in each row
input=train.scp

#### Directory to save .pkl file
output=featurized

#### Include start and end markers to the labels.
#start_marker=^
#Send_marker=$$